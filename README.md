# Visual-Question-Answering-with-YOLO
Implementing Hierarchical Question-Image Co-Attention for Visual Question Answering with YOLO and Back Translation

* This work extends two enhancements to the existing Hierarchical Question-Image Co-Attention for Visual Question Answering [1]

  1) Image features extracted using CNN pre-trained on ImageNet(Xception) and with object features extracted from the YOLOV4 model pre-trained on MS COCO inspired by [2]
  2) Expanding the training dataset using Back Translation text data augmentation method. 
  
 
 
 References: 
 
 [1] Lu, Jiasen, Jianwei Yang, Dhruv Batra, and Devi Parikh. ”Hierarchical question-image co-attention for visual question answering.” Advances in neural information processing systems 29 (2016)
 
 [2] Al-Malla, Muhammad Abdelhadie, Assef Jafar, and Nada Ghneim. ”Image captioning model using attention and object features to mimic human image understanding.” Journal of Big Data 9, no. 1 (2022): 1-16.
